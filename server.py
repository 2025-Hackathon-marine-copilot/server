from flask import Flask, request, jsonify
import os
import numpy as np
import cv2
import tensorflow as tf
from tensorflow import keras

# ===============================
# YOLO ëª¨ë¸ íŒŒì¼ ê²½ë¡œ ì„¤ì •
# ===============================
YOLO_WEIGHTS = "./AI/CRNN/od/yolov4_nia_od.weights"
YOLO_CFG = "./AI/CRNN/od/yolov4_nia_od.cfg"
YOLO_CLASSES = "./AI/CRNN/od/yolov4_nia_od.names"

# CRNNì—ì„œ ì¶œë ¥í•  Output ì¹´í…Œê³ ë¦¬ ë¦¬ìŠ¤íŠ¸ (OCR ê°€ëŠ¥í•œ ë¬¸ì)
categories = ["0", "1", "2", "3", "4", "5", "6", "7", "8", "9",
              "A", "B", "C", "D", "E", "F", "G", "H", "I", "J", "K", "L", "M",
              "N", "O", "P", "Q", "R", "S", "T", "U", "V", "W", "X", "Y", "Z", "_"]

# OCR ì˜ˆì¸¡ëœ ìˆ«ì ì¸ë±ìŠ¤ë¥¼ ë¬¸ìë¡œ ë³€í™˜í•˜ëŠ” StringLookup ìƒì„±
num_to_char = keras.layers.StringLookup(
    vocabulary=categories, num_oov_indices=1, mask_token=None, invert=True
)

# ===============================
# CRNN ëª¨ë¸ ë¡œë“œ ë° ì…ë ¥ ë¬¸ì œ í•´ê²°
# ===============================
crnn_model = tf.keras.models.load_model("./AI/CRNN/20220104-1")

# ì˜ˆì¸¡ìš© ëª¨ë¸ (label ì…ë ¥ ì œê±°)
prediction_model = keras.models.Model(
    inputs=crnn_model.get_layer(name="image").input,
    outputs=crnn_model.get_layer(name="dense2").output
)

# ===============================
# YOLO ëª¨ë¸ ë¡œë“œ
# ===============================
with open(YOLO_CLASSES, "r") as f:
    classes = [line.strip() for line in f.readlines()]

net = cv2.dnn.readNet(YOLO_WEIGHTS, YOLO_CFG)
net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)
net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)

layer_names = net.getLayerNames()
output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]

# ===============================
# OCR ê²°ê³¼ ë””ì½”ë”© í•¨ìˆ˜ (CTC Decode)
# ===============================
def decode_predictions(preds):
    """CRNN ëª¨ë¸ì˜ ì¶œë ¥ì„ ë¬¸ìì—´ë¡œ ë³€í™˜"""
    input_len = np.ones(preds.shape[0]) * preds.shape[1]
    results = keras.backend.ctc_decode(preds, input_length=input_len, greedy=True)[0][0]

    decoded_texts = []
    for res in results:
        res = tf.strings.reduce_join([num_to_char(x) for x in res if x != -1]).numpy().decode("utf-8")
        res = res.replace("[UNK]", "").replace("_", "")
        decoded_texts.append(res)

    return decoded_texts

# ===============================
# OCR ìˆ˜í–‰ í•¨ìˆ˜ (ì´ë¯¸ì§€ ê°œì„  í¬í•¨)
# ===============================
def ocr_with_crnn(image):
    """ì´ë¯¸ì§€ë¥¼ CRNN OCR ëª¨ë¸ì— ì…ë ¥í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ì˜ˆì¸¡í•˜ëŠ” í•¨ìˆ˜"""
    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # í‘ë°± ë³€í™˜
    image = cv2.resize(image, (75, 375))  # âœ… ëª¨ë¸ì´ ê¸°ëŒ€í•˜ëŠ” í¬ê¸°ë¡œ ë³€í™˜
    image = image / 255.0  # ì •ê·œí™”
    image = np.expand_dims(image, axis=-1)  # ì±„ë„ ì°¨ì› ì¶”ê°€ (H, W, C)
    image = np.expand_dims(image, axis=0)  # ë°°ì¹˜ ì°¨ì› ì¶”ê°€ (1, H, W, C)

    preds = prediction_model.predict(image)
    decoded_texts = decode_predictions(preds)
    
    return decoded_texts[0]  # ìµœì¢… OCR ë¬¸ìì—´ ë°˜í™˜

# ===============================
# YOLOë¥¼ ì´ìš©í•œ ê°ì²´ íƒì§€ ë° OCR ìˆ˜í–‰
# ===============================
def detect_and_ocr(image_path):
    result = []
    """YOLOë¥¼ ì´ìš©í•´ ê°ì²´ë¥¼ íƒì§€í•˜ê³ , CRNNì„ í†µí•´ OCRì„ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜"""
    image = cv2.imread(image_path)
    if image is None:
        print("âŒ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return

    height, width, _ = image.shape
    blob = cv2.dnn.blobFromImage(image, 0.00392, (608, 608), (0, 0, 0), True, crop=False)

    net.setInput(blob)
    detections = net.forward(output_layers)

    detected_boxes = []
    
    # YOLO ê²€ì¶œ ê²°ê³¼ ì²˜ë¦¬
    for detection in detections:
        for obj in detection:
            scores = obj[5:]
            class_id = np.argmax(scores)
            confidence = scores[class_id]
            if confidence > 0.5 and classes[class_id] in ["BIC", "TYPESIZE"]:
                center_x, center_y, w, h = map(int, obj[:4] * [width, height, width, height])
                x, y = center_x - w // 2, center_y - h // 2
                
                x, y = max(0, x), max(0, y)
                w, h = min(width - x, w), min(height - y, h)
                
                detected_boxes.append((x, y, w, h))

    # OCR ìˆ˜í–‰
    for idx, (x, y, w, h) in enumerate(detected_boxes):
        roi = image[y:y+h, x:x+w]
        if roi.size == 0:
            continue
        ocr_result = ocr_with_crnn(roi)  # âœ… idx ì œê±°
        result.append(ocr_result)
        print(f"OCR ê²°ê³¼ [{idx}]: {ocr_result}")
    
    return result


app = Flask(__name__)

# ğŸ“Œ ğŸ“¸ OCR ì‹¤í–‰ API
@app.route("/predictLogistics", methods=["POST"])
def predict_logistics():
    data = request.get_json()
    image_path = data.get("image_path")

    if not os.path.exists(image_path):
        return jsonify({"status": "error", "message": "ì´ë¯¸ì§€ ê²½ë¡œê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤."}), 400

    ocr_result = detect_and_ocr(image_path)
    print("ê²°ê³¼", ocr_result)
    return jsonify({"ocr_results": ocr_result})

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=9000, debug=True)